
\documentclass{article}

% latex packages, feel free to add more here like 'tikz'
\usepackage{style/conference}
\usepackage{opensans}
\usepackage{graphicx}
\usepackage{biblatex}
\usepackage{fontawesome}
\usepackage[hidelinks]{hyperref}

% to reference, paste the BibTeX obtained from google scholar into references.bib
\addbibresource{references.bib}
\input{style/math_commands.tex}

% replace this title with your own
\title{Winged Horses with an Autoencoder}

\begin{document}
\maketitle
\begin{abstract}
    This paper proposes using an autoencoder to generate images that look like a Pegasus. 
    I train an autoencoder, and condition it on birds and horses, identified by the annotated class labels for each image. 
    This gives two latent codes via the encoder network which I linearly interpolate between to give the final outputs 
    via the decoder network. 
    This abstract should be short and concise, about 8-10 lines long.
\end{abstract}

% this is where the sections begin
\section{Methodology}
The method is to train an autoencoder~\cite{kramer1991nonlinear}, by minimising the squared L2 loss:
\begin{equation}
    \mathcal{L}_{\textrm{AE}} = \mathbb{E}_{\vx\sim p_{\textrm{data}}}[\, \lVert \vx - D(E(\vx)) \rVert^2 ]
\end{equation}
The encoder function $E : \mathbb{R}^n \rightarrow\mathbb{R}^m$ compresses the dimensionality of the data $n << m$ to a latent encoding 
$z = E(x)$, which is then recovered by the decoder $D: \mathbb{R}^m \rightarrow \mathbb{R}^n$, where $\hat{x} = D(z)$. 

The autoencoder is conditioned on birds and horses which are identified by the annotated class labels available for the images. 
This gives two latent codes via the encoder network which are linearly interpolated between to give the final outputs via the decoder network. 

I use 3 channels and a latent size of 512 and a learning rate of 0.001 in the optimiser with 20 epochs.

The autoencoder can be visualised as below: 
\begin{center}
    \includegraphics[width=0.5\textwidth]{figures/architecture.pdf}
\end{center}
Where the neural network is trained to predict its inputs, thus learning an identity which it can reproduce as its output. 
The architectural diagram above was created using Inkscape and exported to a PDF. 

\section{Results}
The results look very blurry, where the best batch of images looks like this:
\begin{center}
    \includegraphics[width=0.5\textwidth]{figures/best-batch.png}
\end{center}
From this batch, the most Pegasus-like image (with quite a stretch of the imagination) is:
\begin{center}
    \includegraphics[width=0.075\textwidth]{figures/best-pegasus.png}
\end{center}

\section{Limitations}
It's very difficult to see anything that looks like a Pegasus. 
In the future, this could be improved by training for more than 10 epochs, 
although this was not possible due to the time constraints.

\section*{Bonuses}
This submission has a total bonus of +3 marks, as it is trained with STL-10 at the full 96x96 pixels, and the Pegasus has a dark body colour.

% you can have an unlimited number of references (they can go on the 5th page and span many additional pages without any penalty)
\printbibliography
\end{document}
