
\documentclass{article}

\usepackage{style/conference}
\usepackage{opensans}
\usepackage{graphicx}
\usepackage{biblatex}
\usepackage{fontawesome}
\usepackage[hidelinks]{hyperref}

\addbibresource{references.bib}
\input{style/math_commands.tex}

\title{Winged Horses with an Autoencoder}

\begin{document}
\maketitle
\begin{abstract}
    This paper proposes using an autoencoder to generate images that look like a Pegasus. 
    I train an autoencoder, and condition it on birds and horses, identified by the annotated class labels for each image. 
    This gives two latent codes via the encoder network which I linearly interpolate between to give the final outputs 
    via the decoder network. 
\end{abstract}

\section{Methodology}
The method is to train an autoencoder ~\cite{kramer1991nonlinear}, by minimising the squared L2 loss:
\begin{equation}
    \mathcal{L}_{\textrm{AE}} = \mathbb{E}_{\vx\sim p_{\textrm{data}}}[\, \lVert \vx - D(E(\vx)) \rVert^2 ]
\end{equation}
The encoder function $E : \mathbb{R}^n \rightarrow\mathbb{R}^m$ compresses the dimensionality of the data $n \ll m$ to a latent encoding 
$z = E(x)$, which is then recovered by the decoder $D: \mathbb{R}^m \rightarrow \mathbb{R}^n$, where $\hat{x} = D(z)$. 
The autoencoder is conditioned on birds and horses which are identified by the annotated class labels available for the images. 
This was done by creating a mask from the data source of items which were labelled as either a bird or a horse, 
and then applying this to the dataset in order to sample only the appropriate images. 
The latent codes generated by the encoder for the two classes are linearly interpolated between to give the final 
outputs via the decoder network. 

The method was developed on the CIFAR-10 dataset \cite{krizhevsky2009learning} and then tested on the STL-10 dataset \cite{pmlr-v15-coates11a}. 
This is because the images in the CIFAR dataset are only 32x32 pixels, so are much faster to train on, meaning that any errors in the 
method during development would become apparent much more quickly. 
Adjustments had to be made to the autoencoder to accommodate the change from 32x32 images with CIFAR to 96x96 images with STL, 
this included an extra convolution block in both the encoding and decoding stages in order to achieve the correct latent space size. 
Without this extra block, the output images contained unnaturally large blocks of similarly coloured pixels because the latent space was too large. 

As visualisation of the autoencoder is as below: 
\begin{center}
    \includegraphics[width=0.5\textwidth]{figures/architecture.pdf}
\end{center}
Where 'E' is the encoder, 'D' the decoder, and the block in the middle is the latent space 
containing the encoded data, which in this case has size 512. 

The neural network is trained to predict its inputs, thus learning an identity which it can reproduce as its output. 

\section{Results}
The method ran for 100 epochs on the STL-10 dataset at full resolution, with a learning rate of 0.001. 
The results look very blurry, where the best batch of images looks like this:
\begin{center}
    \includegraphics[width=0.5\textwidth]{figures/best-batch.png}
\end{center}
From this batch, the most Pegasus-like image (with quite a stretch of the imagination) is:
\begin{center}
    \includegraphics[width=0.075\textwidth]{figures/best-pegasus.png}
\end{center}
This is a white pegasus stood towards the left side of the image and facing to the left (if you use your imagination). 

\section{Limitations}
It's very difficult to see anything that looks like a Pegasus. 
In the future, this could be improved by training for more than 100 epochs, 
although this was not possible due to the time constraints. 
The majority of the winged horses in the batch are not white, this could be improved by manually selecting white birds 
and white horses from the dataset on which to train, rather than sampling randomly, 
however this was also not possible due to the time constraints. 

\section*{Bonuses}
This submission has a total bonus of +3 marks, as it is trained with STL-10 at the full 96x96 pixels.

\printbibliography
\end{document}
